{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28f7fa2",
   "metadata": {},
   "source": [
    "![ga4](https://www.google-analytics.com/collect?v=2&tid=G-6VDTYWLKX6&cid=1&en=page_view&sid=1&dl=statmike%2Fvertex-ai-mlops%2F01+-+Data+Sources&dt=01+-+BigQuery+-+Table+Data+Source.ipynb)\n",
    "\n",
    "# 01 - BigQuery - Table Data Source\n",
    "Use BigQuery to load and prepare data for machine learning:\n",
    "\n",
    "**Video Walkthrough of this notebook:**\n",
    "\n",
    "Includes conversational walkthrough and more explanatory information than the notebook:\n",
    "<p align=\"center\" width=\"100%\"><center><a href=\"https://youtu.be/Z5whg20WvS8\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"../architectures/thumbnails/playbutton/01.png\" width=\"40%\"></a></center></p>\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [00 - Environment Setup](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Download BigQuery Data to Pandas](https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas)\n",
    "-  [BigQuery Template Notebooks](https://github.com/GoogleCloudPlatform/bigquery-notebooks/tree/main/notebooks/official/template_notebooks)\n",
    "- Using BigQuery From Python, Notebooks in This Repository:\n",
    "    - [Tips/BigQuery - Python Client](../Tips/BigQuery%20-%20Python%20Client.ipynb)\n",
    "    - [03 - BigQuery ML (BQML)/Introduction to BigQuery ML (BQML)](../03%20-%20BigQuery%20ML%20(BQML)/Introduction%20to%20BigQuery%20ML%20(BQML).ipynb)\n",
    "    - [Applied Forecasting/1 - BigQuery Time Series Forecasting Data Review and Preparation](../Applied%20Forecasting/1%20-%20BigQuery%20Time%20Series%20Forecasting%20Data%20Review%20and%20Preparation.ipynb)\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/01_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/01_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c695d-002d-48ca-9d52-839f95fdfee0",
   "metadata": {},
   "source": [
    "---\n",
    "## Source Data\n",
    "\n",
    "**Overview**\n",
    "\n",
    "This notebook imports source data for this project into Google BigQuery.  All the remaining notebooks utilize BigQuery as the source and leverage API's native to the machine learning approaches they feature.\n",
    "\n",
    "This notebook, `01 - BigQuery - Table Data Source`, starts the machine learning lifecycle by exporting a BigQuery source table to CSV format in a Cloud Storage Bucket, then importing source data and preparing it for machine learning.\n",
    "\n",
    "All of these workflows utilize tabular data to fit a supervised learning model: predict a target variable by learning patterns in feature columns.  The type of supervised learning used in these projects is classification: models with a target variable that has multiple discrete classes.  \n",
    "\n",
    "**The Data**\n",
    "\n",
    "The source data is first exported to Google Cloud Storage in CSV format below.  The BigQuery source table is `bigquery-public-data.ml_datasets.ulb_fraud_detection`.  This is a table of credit card transactions that are classified as fradulant, `Class = 1`, or normal `Class = 0`.    \n",
    "- The data can be researched further at this [Kaggle link](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
    "- Read mode about BigQuery public datasets [here](https://cloud.google.com/bigquery/public-data)\n",
    "\n",
    "**Description of the Data**\n",
    "\n",
    "This is a table of 284,807 credit card transactions classified as fradulant or normal in the column `Class`.  In order protect confidentiality, the original features have been transformed using [principle component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) into 28 features named `V1, V2, ... V28` (float).  Two descriptive features are provided without transformation by PCA:\n",
    "- `Time` (integer) is the seconds elapsed between the transaction and the earliest transaction in the table\n",
    "- `Amount` (float) is the value of the transaction\n",
    ">**Quick Note on PCA**<p>PCA is an unsupervised learning technique: there is not a target variable.  PCA is commonlly used as a variable/feature reduction technique.  If you have 100 features then you could reduce it to a number p (say 10) projected features.  The choice of this number is a balance of how well it can explain the variance of the full feature space and reducing the number of features.  Each projected feature is orthogonal to each other feature, meaning there is no correlation between these new projected features.</p>\n",
    "\n",
    "**Preparation of the Data**\n",
    "\n",
    "This notebook adds two columns to the source data and stores it in a new table with suffix `_prepped`.  \n",
    "- `transaction_id` (string) a unique id for the row/transaction\n",
    "- `splits` (string) this divided the tranactions into sets for `TRAIN` (80%), `VALIDATE` (10%), and `TEST` (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5046940",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae60b2",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f0503a-e864-4170-ade9-0ebabd14efcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avid-streamer-396319'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a5bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '01'\n",
    "SERIES = '01'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud'\n",
    "\n",
    "# Data source for this series of notebooks: Described above\n",
    "BQ_SOURCE = 'bigquery-public-data.ml_datasets.ulb_fraud_detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a963be",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a37b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cebb6",
   "metadata": {},
   "source": [
    "Create clients and authenticated to our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e515410",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6601398",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f1e2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c3a89-d98f-471c-ae54-3b9157651f0b",
   "metadata": {},
   "source": [
    "---\n",
    "## Store the Source Data in GCS Storage Bucket\n",
    "Check to see if the export exist and create if not:\n",
    "- export from bigquery table to GCS bucket as CSV\n",
    "    - the table is referenced in the `BQ_SOURCE` variable at the top of this notebook\n",
    "- [Exporting Table Data](https://cloud.google.com/bigquery/docs/exporting-data#python)\n",
    "- [BigQuery Python Client](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client#google_cloud_bigquery_client_Client_extract_table)\n",
    "\n",
    "For more tips on interacting with GCS using the Python Client review the tips notebook [Python Client for GCS](../Tips/Python%20Client%20for%20GCS.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6144857f-1ecc-4712-925b-4de69b6df0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"{SERIES}/{EXPERIMENT}/data/{BQ_TABLE}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65714181-b946-4c5c-b990-6f7ac4f2ca2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the export ...\n",
      "Exported the table to: gs://avid-streamer-396319/01/01/data/fraud.csv\n"
     ]
    }
   ],
   "source": [
    "bucketDef = gcs.bucket(BUCKET)\n",
    "#check if the file exists in the bucket\n",
    "if storage.Blob(bucket = bucketDef, name = file).exists(gcs):\n",
    "    print(f'The file has already been created at: gs://{bucketDef.name}/{file}')\n",
    "else:\n",
    "    source = bigquery.TableReference.from_string(BQ_SOURCE)\n",
    "    extract = bq.extract_table(source = source, destination_uris = [f'gs://{bucketDef.name}/{file}'])\n",
    "    print('Creating the export ...')\n",
    "    extract.result()\n",
    "    print(f'Exported the table to: gs://{bucketDef.name}/{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c19f8-677e-4219-a0ff-bcfe1fd932a0",
   "metadata": {},
   "source": [
    "list files in the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed784872-405b-4d64-a70b-4482529b5fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: avid-streamer-396319, 01/01/data/fraud.csv, 1692640692335676>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bucketDef.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f40c2ea7-0649-4073-88a4-3e47af62f0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the files in the console here:\n",
      "https://console.cloud.google.com/storage/browser/avid-streamer-396319/01;tab=objects&project=avid-streamer-396319\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the files in the console here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SERIES};tab=objects&project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685eddc",
   "metadata": {},
   "source": [
    "---\n",
    "## Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725b37b-2664-44bd-bf18-0704e3fe85c7",
   "metadata": {},
   "source": [
    "We have Projects => Buckets (datasets that organize infos) => assets (table: rows/cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cab37",
   "metadata": {},
   "source": [
    "List BigQuery datasets in the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b49b948-5fa8-4d4e-a7d3-b2adb19362c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(bq.list_datasets())\n",
    "for d in datasets:\n",
    "    print(d.dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b3aca",
   "metadata": {},
   "source": [
    "Create the dataset if missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61001b78-418f-42a1-a4c4-d74a1f3aff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "ds.location = REGION\n",
    "ds.labels = {'experiment': f'{EXPERIMENT}'}\n",
    "ds = bq.create_dataset(dataset = ds, exists_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a50638-515e-49d0-b479-25e92138ae96",
   "metadata": {},
   "source": [
    "List BigQuery datasets in the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b39f4471-38f4-4b97-8d9c-7ee3122dbee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud\n"
     ]
    }
   ],
   "source": [
    "datasets = list(bq.list_datasets())\n",
    "for d in datasets:\n",
    "    print(d.dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40929c96-3907-4771-bf30-462c75f559f1",
   "metadata": {},
   "source": [
    "go to BigQuery => check the fraud dataset under the project name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eeac68",
   "metadata": {},
   "source": [
    "---\n",
    "## Create BigQuery Table inside Fraud dataset\n",
    "- import data from Cloud Storage Bucket\n",
    "- [Loading CSV data from Cloud Storage](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv)\n",
    "- [BigQuery Python Client](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client#google_cloud_bigquery_client_Client_extract_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86063a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Table ...\n",
      "Finished creating table: avid-streamer-396319.fraud.fraud\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.exceptions import NotFound\n",
    "try:\n",
    "    table = bq.get_table(f'{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')\n",
    "    if table:\n",
    "        print(f'The table already exists: {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')\n",
    "except NotFound as error:\n",
    "    print(f'Creating Table ...')\n",
    "    destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\")\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition = 'WRITE_TRUNCATE',\n",
    "        source_format = bigquery.SourceFormat.CSV,\n",
    "        autodetect = True, #detect cols types auto\n",
    "        labels = {'experiment': f'{EXPERIMENT}'}\n",
    "    )\n",
    "    job = bq.load_table_from_uri(f\"gs://{bucketDef.name}/{file}\", destination, job_config = job_config)\n",
    "    job.result()\n",
    "    print(f'Finished creating table: {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44285e37-6ac7-478d-9709-dd11a068a4dc",
   "metadata": {},
   "source": [
    "### Retrieve and Review a Sample From The Table:\n",
    "> **Note:** The `LIMIT 5` statement does limit the number of rows returned by BigQuery to 5 but BigQuery still does a full table scan.  If you have a table larger than 1GB and want to limit the rows scanned for a quick review like then then replacing `LIMIT 5` with `TABLESAMPLE SYSTEM (1 PERCENT)` would be more efficient.  For tables under 1GB it will still return the full table.  More on [Table Sampling](https://cloud.google.com/bigquery/docs/table-sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11924cf8-a040-4ee5-85ae-788cba106b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150336</td>\n",
       "      <td>2.030851</td>\n",
       "      <td>-0.235559</td>\n",
       "      <td>-2.804940</td>\n",
       "      <td>-0.547376</td>\n",
       "      <td>2.441730</td>\n",
       "      <td>3.277629</td>\n",
       "      <td>-0.652959</td>\n",
       "      <td>0.843118</td>\n",
       "      <td>0.542395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058377</td>\n",
       "      <td>-0.092950</td>\n",
       "      <td>0.203618</td>\n",
       "      <td>0.642094</td>\n",
       "      <td>-0.105975</td>\n",
       "      <td>0.502090</td>\n",
       "      <td>-0.024706</td>\n",
       "      <td>-0.040995</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84068</td>\n",
       "      <td>-0.679466</td>\n",
       "      <td>1.334849</td>\n",
       "      <td>1.367987</td>\n",
       "      <td>0.856085</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-0.701735</td>\n",
       "      <td>0.582134</td>\n",
       "      <td>-0.003885</td>\n",
       "      <td>-0.741823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077499</td>\n",
       "      <td>0.311384</td>\n",
       "      <td>-0.095417</td>\n",
       "      <td>0.413387</td>\n",
       "      <td>-0.212580</td>\n",
       "      <td>-0.457638</td>\n",
       "      <td>-0.250283</td>\n",
       "      <td>-0.139162</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122091</td>\n",
       "      <td>2.141596</td>\n",
       "      <td>0.077735</td>\n",
       "      <td>-2.104923</td>\n",
       "      <td>0.061232</td>\n",
       "      <td>0.368903</td>\n",
       "      <td>-1.825884</td>\n",
       "      <td>0.748172</td>\n",
       "      <td>-0.564815</td>\n",
       "      <td>0.354072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131269</td>\n",
       "      <td>0.490071</td>\n",
       "      <td>-0.035338</td>\n",
       "      <td>0.008649</td>\n",
       "      <td>0.415350</td>\n",
       "      <td>0.245709</td>\n",
       "      <td>-0.091809</td>\n",
       "      <td>-0.081979</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136167</td>\n",
       "      <td>2.073311</td>\n",
       "      <td>0.265580</td>\n",
       "      <td>-1.745544</td>\n",
       "      <td>0.492756</td>\n",
       "      <td>0.286109</td>\n",
       "      <td>-1.427709</td>\n",
       "      <td>0.310907</td>\n",
       "      <td>-0.422277</td>\n",
       "      <td>0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191552</td>\n",
       "      <td>0.767662</td>\n",
       "      <td>-0.043917</td>\n",
       "      <td>-0.156863</td>\n",
       "      <td>0.295408</td>\n",
       "      <td>-0.096150</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>-0.031715</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150523</td>\n",
       "      <td>2.032967</td>\n",
       "      <td>-0.387542</td>\n",
       "      <td>-0.505876</td>\n",
       "      <td>0.350922</td>\n",
       "      <td>-0.424833</td>\n",
       "      <td>-0.134032</td>\n",
       "      <td>-0.623411</td>\n",
       "      <td>-0.005357</td>\n",
       "      <td>1.481508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151034</td>\n",
       "      <td>0.737664</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>-0.682962</td>\n",
       "      <td>-0.007459</td>\n",
       "      <td>-0.166488</td>\n",
       "      <td>0.047286</td>\n",
       "      <td>-0.044997</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  150336  2.030851 -0.235559 -2.804940 -0.547376  2.441730  3.277629   \n",
       "1   84068 -0.679466  1.334849  1.367987  0.856085  0.000189 -0.701735   \n",
       "2  122091  2.141596  0.077735 -2.104923  0.061232  0.368903 -1.825884   \n",
       "3  136167  2.073311  0.265580 -1.745544  0.492756  0.286109 -1.427709   \n",
       "4  150523  2.032967 -0.387542 -0.505876  0.350922 -0.424833 -0.134032   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0 -0.652959  0.843118  0.542395  ... -0.058377 -0.092950  0.203618  0.642094   \n",
       "1  0.582134 -0.003885 -0.741823  ...  0.077499  0.311384 -0.095417  0.413387   \n",
       "2  0.748172 -0.564815  0.354072  ...  0.131269  0.490071 -0.035338  0.008649   \n",
       "3  0.310907 -0.422277  0.505541  ...  0.191552  0.767662 -0.043917 -0.156863   \n",
       "4 -0.623411 -0.005357  1.481508  ...  0.151034  0.737664  0.044700 -0.682962   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0 -0.105975  0.502090 -0.024706 -0.040995    0.78      0  \n",
       "1 -0.212580 -0.457638 -0.250283 -0.139162    0.78      0  \n",
       "2  0.415350  0.245709 -0.091809 -0.081979    0.78      0  \n",
       "3  0.295408 -0.096150  0.002101 -0.031715    0.78      0  \n",
       "4 -0.007459 -0.166488  0.047286 -0.044997    0.78      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` TABLESAMPLE SYSTEM (1 PERCENT)\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ccdce-e6a9-4735-9997-e5ae77a6f86c",
   "metadata": {},
   "source": [
    "### Check out this table in BigQuery Console:\n",
    "- Click: https://console.cloud.google.com/bigquery\n",
    "- Make sure project selected is the one from this notebook\n",
    "- Under Explore, expand this project and review the dataset and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d439a1dc-dfdd-4c82-8302-8dc1ffe44d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Link To This Project In BigQuery:\n",
      "https://console.cloud.google.com/bigquery?project=avid-streamer-396319\n"
     ]
    }
   ],
   "source": [
    "print(f\"Direct Link To This Project In BigQuery:\\nhttps://console.cloud.google.com/bigquery?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f133efb-8232-4b21-814f-23b815dc60f2",
   "metadata": {},
   "source": [
    "---\n",
    "## Review Data in BigQuery\n",
    "Additional SQL queries could be used to review the data.  This section shows moving the table to a Pandas dataframe for local review in Python:\n",
    "\n",
    "> **Note:** <p>This query only selects one column.  This means BigQuery scans less data as it does not process the other columns.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4ebf6f5-a178-4011-9ab6-fa8329c578c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT Class\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "\"\"\"\n",
    "df = bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "674f716e-8b9d-4c92-9b46-c166b869f6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba5d17e5-07c3-48fd-b682-aa471f3548f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: proportion, dtype: Float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b34894",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare Data for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c982157",
   "metadata": {},
   "source": [
    "Create a prepped version of the data with test/train splits using SQL DDL: we will create new table from the existing table.\n",
    "\n",
    "- FARM_FINGERPRINT: generates big integer => /10 and keep remainder = [0-9] => 80% as train, 10% for test and valid\n",
    "- We use this splitting approach to allow every user to have the same sets for train/ test/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a50becbb-60ab-45f9-acd5-9beb5b6755f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7ff6011c3550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped` AS\n",
    "WITH add_id AS(SELECT *, GENERATE_UUID() transaction_id FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`) #create unique id for each row / add_id is a dummy table\n",
    "SELECT *,\n",
    "    CASE\n",
    "        WHEN MOD(ABS(FARM_FINGERPRINT(transaction_id)),10) < 8 THEN \"TRAIN\" \n",
    "        WHEN MOD(ABS(FARM_FINGERPRINT(transaction_id)),10) < 9 THEN \"VALIDATE\"\n",
    "        ELSE \"TEST\"\n",
    "    END AS splits\n",
    "FROM add_id\n",
    "\"\"\"\n",
    "job = bq.query(query = query)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77d6e2a9-ec35-477c-9d50-429326acc41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.48"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(job.ended-job.started).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a991ff73-a545-4eed-a709-b8292efd89ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.632136 MB\n"
     ]
    }
   ],
   "source": [
    "if job.estimated_bytes_processed:\n",
    "    print(f'{job.estimated_bytes_processed/1000000} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b2c41",
   "metadata": {},
   "source": [
    "Review the test/train split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a94adb9-81d7-4710-ac50-e0d93dd5523a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>splits</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VALIDATE</td>\n",
       "      <td>28630</td>\n",
       "      <td>10.052421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST</td>\n",
       "      <td>28310</td>\n",
       "      <td>9.940065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>227867</td>\n",
       "      <td>80.007514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     splits   Count  Percentage\n",
       "0  VALIDATE   28630   10.052421\n",
       "1      TEST   28310    9.940065\n",
       "2     TRAIN  227867   80.007514"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT splits, count(*) as Count, 100*count(*) / (sum(count(*)) OVER()) as Percentage\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped`\n",
    "GROUP BY splits\n",
    "\"\"\"\n",
    "bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006ed11",
   "metadata": {},
   "source": [
    "Retrieve a subset of the data to a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ea70141-07db-46b0-a31e-0968befcd37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT * \n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped`\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "data = bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "326d2b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119592</td>\n",
       "      <td>2.139741</td>\n",
       "      <td>0.245651</td>\n",
       "      <td>-2.654856</td>\n",
       "      <td>0.178287</td>\n",
       "      <td>1.336991</td>\n",
       "      <td>-0.724664</td>\n",
       "      <td>0.906032</td>\n",
       "      <td>-0.436125</td>\n",
       "      <td>-0.528015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216033</td>\n",
       "      <td>0.345316</td>\n",
       "      <td>0.747103</td>\n",
       "      <td>0.700184</td>\n",
       "      <td>-0.123739</td>\n",
       "      <td>-0.099989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>c1908dfc-b9fe-4329-947f-ce1d8b705ac3</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129420</td>\n",
       "      <td>-0.539919</td>\n",
       "      <td>1.273124</td>\n",
       "      <td>0.987345</td>\n",
       "      <td>2.207887</td>\n",
       "      <td>0.827857</td>\n",
       "      <td>1.099094</td>\n",
       "      <td>0.154173</td>\n",
       "      <td>0.567619</td>\n",
       "      <td>-1.140350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039536</td>\n",
       "      <td>0.308004</td>\n",
       "      <td>-1.128751</td>\n",
       "      <td>-0.291094</td>\n",
       "      <td>-0.157021</td>\n",
       "      <td>-0.031830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>f97a4ab2-dfa3-4745-bfb5-19796e93f0c1</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75176</td>\n",
       "      <td>1.235603</td>\n",
       "      <td>0.041383</td>\n",
       "      <td>0.675286</td>\n",
       "      <td>0.836279</td>\n",
       "      <td>-0.675016</td>\n",
       "      <td>-0.657342</td>\n",
       "      <td>-0.154209</td>\n",
       "      <td>-0.067491</td>\n",
       "      <td>0.602617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088164</td>\n",
       "      <td>0.396205</td>\n",
       "      <td>0.324557</td>\n",
       "      <td>0.182930</td>\n",
       "      <td>-0.017115</td>\n",
       "      <td>0.014979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41e4cf07-f271-45fe-babe-88af8c4a9d69</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167575</td>\n",
       "      <td>1.808792</td>\n",
       "      <td>-0.632766</td>\n",
       "      <td>-0.547739</td>\n",
       "      <td>0.142396</td>\n",
       "      <td>0.222408</td>\n",
       "      <td>1.824899</td>\n",
       "      <td>-1.068149</td>\n",
       "      <td>0.721798</td>\n",
       "      <td>0.914282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262650</td>\n",
       "      <td>-1.741824</td>\n",
       "      <td>-0.606627</td>\n",
       "      <td>0.493312</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>-0.075780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ec304a05-c031-43ab-a903-461cd394de99</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2891</td>\n",
       "      <td>-1.356410</td>\n",
       "      <td>0.434828</td>\n",
       "      <td>3.176296</td>\n",
       "      <td>2.542596</td>\n",
       "      <td>0.250651</td>\n",
       "      <td>0.471825</td>\n",
       "      <td>-0.042386</td>\n",
       "      <td>0.066513</td>\n",
       "      <td>-0.451823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019940</td>\n",
       "      <td>0.423206</td>\n",
       "      <td>0.036699</td>\n",
       "      <td>0.059171</td>\n",
       "      <td>-0.253716</td>\n",
       "      <td>-0.105177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5f3e52ef-8e16-474b-a2c1-40a2f4ddac4d</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  119592  2.139741  0.245651 -2.654856  0.178287  1.336991 -0.724664   \n",
       "1  129420 -0.539919  1.273124  0.987345  2.207887  0.827857  1.099094   \n",
       "2   75176  1.235603  0.041383  0.675286  0.836279 -0.675016 -0.657342   \n",
       "3  167575  1.808792 -0.632766 -0.547739  0.142396  0.222408  1.824899   \n",
       "4    2891 -1.356410  0.434828  3.176296  2.542596  0.250651  0.471825   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0  0.906032 -0.436125 -0.528015  ... -0.216033  0.345316  0.747103  0.700184   \n",
       "1  0.154173  0.567619 -1.140350  ... -0.039536  0.308004 -1.128751 -0.291094   \n",
       "2 -0.154209 -0.067491  0.602617  ...  0.088164  0.396205  0.324557  0.182930   \n",
       "3 -1.068149  0.721798  0.914282  ...  0.262650 -1.741824 -0.606627  0.493312   \n",
       "4 -0.042386  0.066513 -0.451823  ...  0.019940  0.423206  0.036699  0.059171   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0 -0.123739 -0.099989     0.0      0  c1908dfc-b9fe-4329-947f-ce1d8b705ac3   \n",
       "1 -0.157021 -0.031830     0.0      0  f97a4ab2-dfa3-4745-bfb5-19796e93f0c1   \n",
       "2 -0.017115  0.014979     0.0      0  41e4cf07-f271-45fe-babe-88af8c4a9d69   \n",
       "3  0.049780 -0.075780     0.0      0  ec304a05-c031-43ab-a903-461cd394de99   \n",
       "4 -0.253716 -0.105177     0.0      0  5f3e52ef-8e16-474b-a2c1-40a2f4ddac4d   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "4    TEST  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d575d1",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a3c62-b73c-4cce-a6d2-8479c34eea59",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234276fd-a872-427a-95a7-b2e1d2c797c3",
   "metadata": {},
   "source": [
    "##### Do we need to use BigQuery for data source ?\n",
    "no we can use any data source. However, BigQuery is very easy to share and collaborate. It makes it easier to create same data splits for eveyone. It gives usoptions when we want to plug in ML algorithims to a source that might not be able to hold all the data. BigQuery fetches data batches in parallel => local memory doesnt need to be big enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ad2da-d777-438c-ac33-ff198a92f4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
